{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1637b902-d36d-4280-af1c-d7d40c472ce9",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd30c2c1-dce9-46d6-b6ad-a5d4d2140dec",
   "metadata": {},
   "source": [
    "### Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af8712e0-756c-41f4-983e-5d961b2e93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0046afb6-eca7-46a8-9728-73b4b799ef85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.18.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8267e486-1437-421f-b3b6-72d2ffc16bf4",
   "metadata": {},
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8e363-33de-406a-8aee-c83306459a3b",
   "metadata": {},
   "source": [
    "### Importing the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f5b2b5-152e-4ffa-a1ff-8f718d7b0075",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/Churn_Modelling.csv')\n",
    "X = dataset.iloc[:, 3:-1].values # Features (exclude the first 3 columns)\n",
    "y = dataset.iloc[:, -1].values  # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b23a40-c03f-4e53-88e6-07a57a25e6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f7a4c6-72bf-4ff1-b1b9-1cedddcda6ca",
   "metadata": {},
   "source": [
    "### Encoding categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0715cf5-3897-4fba-8356-87005e6957a3",
   "metadata": {},
   "source": [
    "#### Label Encoding the \"Gender\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f83804ff-062e-4e46-81f3-4389ec4ec41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import LabelEncoder\n",
    "#le = LabelEncoder()\n",
    "#X[:, 2] = le.fit_transform(X[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "210112fc-8875-4dc9-957c-6002323ee5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[619, 'France', 'Female', ..., 1, 1, 101348.88],\n",
       "       [608, 'Spain', 'Female', ..., 0, 1, 112542.58],\n",
       "       [502, 'France', 'Female', ..., 1, 0, 113931.57],\n",
       "       ...,\n",
       "       [709, 'France', 'Female', ..., 0, 1, 42085.58],\n",
       "       [772, 'Germany', 'Male', ..., 1, 0, 92888.52],\n",
       "       [792, 'France', 'Female', ..., 1, 0, 38190.78]], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a653d65f-6322-4056-82d5-e3464777d638",
   "metadata": {},
   "source": [
    "#### One Hot Encoding the \"Geography\" column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4d5c502-7ed7-43e6-80f3-d25820c04073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder_location', OneHotEncoder(), [1]), # hot encode the location\n",
    "        ('encoder_gender', OrdinalEncoder(), [2]) # convert the gender to a categorcial value        \n",
    "    ], \n",
    "    remainder='passthrough')\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df1d3275-72ad-401f-bd95-a0473f2128af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3    4   5   6          7  8  9  10         11\n",
       "0     1.0  0.0  0.0  0.0  619  42   2        0.0  1  1  1  101348.88\n",
       "1     0.0  0.0  1.0  0.0  608  41   1   83807.86  1  0  1  112542.58\n",
       "2     1.0  0.0  0.0  0.0  502  42   8   159660.8  3  1  0  113931.57\n",
       "3     1.0  0.0  0.0  0.0  699  39   1        0.0  2  0  0   93826.63\n",
       "4     0.0  0.0  1.0  0.0  850  43   2  125510.82  1  1  1    79084.1\n",
       "...   ...  ...  ...  ...  ...  ..  ..        ... .. .. ..        ...\n",
       "9995  1.0  0.0  0.0  1.0  771  39   5        0.0  2  1  0   96270.64\n",
       "9996  1.0  0.0  0.0  1.0  516  35  10   57369.61  1  1  1  101699.77\n",
       "9997  1.0  0.0  0.0  0.0  709  36   7        0.0  1  0  1   42085.58\n",
       "9998  0.0  1.0  0.0  1.0  772  42   3   75075.31  2  1  0   92888.52\n",
       "9999  1.0  0.0  0.0  0.0  792  28   4  130142.79  1  1  0   38190.78\n",
       "\n",
       "[10000 rows x 12 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0159fec5-7234-4ca4-a08c-dddfd31a4c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0, 0.0, 0.0, 0.0, 619, 42, 2, 0.0, 1, 1, 1, 101348.88],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794562a7-25ef-473d-9660-ec59fe370ae1",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93894ef7-af9d-4731-8941-dccec6c23e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161fd88e-3f15-409c-a7e9-c0cabc79a428",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dbb7a7d-53ee-4281-8f1f-f29f4344acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must do this for neural networking... must be applied to all features IMPORTANT!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "899ae93d-9082-400e-9ccf-6ff755b4e03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train) # only fitted to prevent info leakage\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c548eb2-465e-4bbc-b0b2-d705be184040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.014607</td>\n",
       "      <td>1.754865</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>-1.091687</td>\n",
       "      <td>-0.552043</td>\n",
       "      <td>-0.368904</td>\n",
       "      <td>1.044737</td>\n",
       "      <td>0.879303</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>1.610857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985604</td>\n",
       "      <td>-0.569844</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>-1.091687</td>\n",
       "      <td>-1.314903</td>\n",
       "      <td>0.109617</td>\n",
       "      <td>-1.031415</td>\n",
       "      <td>0.429722</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>-1.032270</td>\n",
       "      <td>0.495870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.014607</td>\n",
       "      <td>-0.569844</td>\n",
       "      <td>1.743090</td>\n",
       "      <td>-1.091687</td>\n",
       "      <td>0.571630</td>\n",
       "      <td>0.301026</td>\n",
       "      <td>1.044737</td>\n",
       "      <td>0.308583</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>-0.424787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.985604</td>\n",
       "      <td>-0.569844</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>0.916013</td>\n",
       "      <td>1.416961</td>\n",
       "      <td>-0.656016</td>\n",
       "      <td>-0.339364</td>\n",
       "      <td>0.575336</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>-1.556190</td>\n",
       "      <td>-1.032270</td>\n",
       "      <td>-0.187777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.014607</td>\n",
       "      <td>1.754865</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>0.916013</td>\n",
       "      <td>0.571630</td>\n",
       "      <td>-0.081791</td>\n",
       "      <td>0.006661</td>\n",
       "      <td>1.389611</td>\n",
       "      <td>0.809503</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>0.616842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.985604</td>\n",
       "      <td>-0.569844</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>-1.091687</td>\n",
       "      <td>-0.263393</td>\n",
       "      <td>-1.421650</td>\n",
       "      <td>-1.377440</td>\n",
       "      <td>-1.215717</td>\n",
       "      <td>0.809503</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>1.404319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.985604</td>\n",
       "      <td>-0.569844</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>-1.091687</td>\n",
       "      <td>-0.665441</td>\n",
       "      <td>-0.368904</td>\n",
       "      <td>0.698712</td>\n",
       "      <td>-1.215717</td>\n",
       "      <td>0.809503</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>-1.032270</td>\n",
       "      <td>-0.511196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>-1.014607</td>\n",
       "      <td>-0.569844</td>\n",
       "      <td>1.743090</td>\n",
       "      <td>0.916013</td>\n",
       "      <td>-0.747912</td>\n",
       "      <td>-0.273200</td>\n",
       "      <td>-1.377440</td>\n",
       "      <td>1.297455</td>\n",
       "      <td>0.809503</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>-1.032270</td>\n",
       "      <td>0.718885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>-1.014607</td>\n",
       "      <td>1.754865</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>0.916013</td>\n",
       "      <td>-0.005670</td>\n",
       "      <td>-0.464608</td>\n",
       "      <td>-0.339364</td>\n",
       "      <td>1.059752</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>0.968738</td>\n",
       "      <td>-1.545078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-1.014607</td>\n",
       "      <td>1.754865</td>\n",
       "      <td>-0.573694</td>\n",
       "      <td>0.916013</td>\n",
       "      <td>-0.799457</td>\n",
       "      <td>-0.847425</td>\n",
       "      <td>1.044737</td>\n",
       "      <td>0.820263</td>\n",
       "      <td>-0.921591</td>\n",
       "      <td>0.642595</td>\n",
       "      <td>-1.032270</td>\n",
       "      <td>1.612559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -1.014607  1.754865 -0.573694 -1.091687 -0.552043 -0.368904  1.044737   \n",
       "1     0.985604 -0.569844 -0.573694 -1.091687 -1.314903  0.109617 -1.031415   \n",
       "2    -1.014607 -0.569844  1.743090 -1.091687  0.571630  0.301026  1.044737   \n",
       "3     0.985604 -0.569844 -0.573694  0.916013  1.416961 -0.656016 -0.339364   \n",
       "4    -1.014607  1.754865 -0.573694  0.916013  0.571630 -0.081791  0.006661   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1995  0.985604 -0.569844 -0.573694 -1.091687 -0.263393 -1.421650 -1.377440   \n",
       "1996  0.985604 -0.569844 -0.573694 -1.091687 -0.665441 -0.368904  0.698712   \n",
       "1997 -1.014607 -0.569844  1.743090  0.916013 -0.747912 -0.273200 -1.377440   \n",
       "1998 -1.014607  1.754865 -0.573694  0.916013 -0.005670 -0.464608 -0.339364   \n",
       "1999 -1.014607  1.754865 -0.573694  0.916013 -0.799457 -0.847425  1.044737   \n",
       "\n",
       "            7         8         9         10        11  \n",
       "0     0.879303 -0.921591  0.642595  0.968738  1.610857  \n",
       "1     0.429722 -0.921591  0.642595 -1.032270  0.495870  \n",
       "2     0.308583 -0.921591  0.642595  0.968738 -0.424787  \n",
       "3     0.575336 -0.921591 -1.556190 -1.032270 -0.187777  \n",
       "4     1.389611  0.809503  0.642595  0.968738  0.616842  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "1995 -1.215717  0.809503  0.642595  0.968738  1.404319  \n",
       "1996 -1.215717  0.809503  0.642595 -1.032270 -0.511196  \n",
       "1997  1.297455  0.809503  0.642595 -1.032270  0.718885  \n",
       "1998  1.059752 -0.921591  0.642595  0.968738 -1.545078  \n",
       "1999  0.820263 -0.921591  0.642595 -1.032270  1.612559  \n",
       "\n",
       "[2000 rows x 12 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c977f5-0f8f-4c8e-acb4-114f4b5ef1e8",
   "metadata": {},
   "source": [
    "## Part 2 - Building the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efa9d5e-c12c-4f8f-abc2-d007de3db058",
   "metadata": {},
   "source": [
    "#### Initializing the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "876fbe8e-ea32-406e-ac77-d474797af326",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = tf.keras.models.Sequential() # keras is part of tensorflow in v2, this initializes our neural network as a sequence of layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc42968-ba2a-469f-a3d8-e999da9fd426",
   "metadata": {},
   "source": [
    "#### Adding the input layer and the first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "899c1314-fca3-493e-b8f5-48b1426be634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Units is the number of neurons in the first hidden layer (first layer are the features)\n",
    "# ReLU is the rectifier activation function\n",
    "# object of the dense class to create the fully connected layer (layers has the tools for adding them)\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c3cb5b-9eb1-4fb1-b64e-c10eede99405",
   "metadata": {},
   "source": [
    "#### Adding the second hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f5b0635-d0a6-4d04-858b-9fa9b603cb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3d0ca3-7d8b-4911-a21b-975411fc6a23",
   "metadata": {},
   "source": [
    "#### Adding the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf9ab6ee-523f-49f5-842a-763db5a0295f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense means fully connected\n",
    "# Also if had 3 categories then 3, but if binary just 1 is fine for 0/1 think hot-encoding for the output\n",
    "\n",
    "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))  # if categorical use softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4f3d30-adb9-4947-aa89-152b5eb4f0a6",
   "metadata": {},
   "source": [
    "## Part 3 - Train the ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a173a5-e229-4f4a-b16d-e7296f3bfb96",
   "metadata": {},
   "source": [
    "#### Compiling the ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5d8a9f8-2194-4c1f-bb06-62a47c87c6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737825914.363363  146974 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6096 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2070 with Max-Q Design, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Need the optimizer, loss function, and metrics\n",
    "# can choose from several metrics to measure during training\n",
    "# optimizer allows for stochastic gradient decent (adam)\n",
    "# loss is way to compute difference (for binary, always use 'binary_crossentropy')\n",
    "# if non-binary, then 'categorical_crossentropy'\n",
    "# metrics are a list of ones to use\n",
    "\n",
    "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e2bcad-a350-44dc-b23b-9b015f0ff7d9",
   "metadata": {},
   "source": [
    "#### Training the ANN on the Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a44e681-6c9a-4241-81e4-c80124ed4343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1737825915.397499  147187 service.cc:148] XLA service 0x7ff48c001940 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1737825915.397698  147187 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 2070 with Max-Q Design, Compute Capability 7.5\n",
      "2025-01-25 11:25:15.435339: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1737825915.572293  147187 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 60/250\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4568 - loss: 0.7750 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1737825916.376462  147187 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.5871 - loss: 0.6707\n",
      "Epoch 2/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8011 - loss: 0.4677 \n",
      "Epoch 3/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7981 - loss: 0.4489 \n",
      "Epoch 4/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.4310 \n",
      "Epoch 5/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8172 - loss: 0.4219 \n",
      "Epoch 6/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8158 - loss: 0.4203 \n",
      "Epoch 7/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8224 - loss: 0.4208 \n",
      "Epoch 8/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8247 - loss: 0.4118 \n",
      "Epoch 9/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8283 - loss: 0.3991 \n",
      "Epoch 10/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.3956 \n",
      "Epoch 11/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3832 \n",
      "Epoch 12/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8304 - loss: 0.3918 \n",
      "Epoch 13/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8276 - loss: 0.3883 \n",
      "Epoch 14/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8345 - loss: 0.3700 \n",
      "Epoch 15/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8261 - loss: 0.3786 \n",
      "Epoch 16/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8416 - loss: 0.3704 \n",
      "Epoch 17/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.3695 \n",
      "Epoch 18/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8499 - loss: 0.3650 \n",
      "Epoch 19/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8496 - loss: 0.3658\n",
      "Epoch 20/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8568 - loss: 0.3566 \n",
      "Epoch 21/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8560 - loss: 0.3531 \n",
      "Epoch 22/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8582 - loss: 0.3551 \n",
      "Epoch 23/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3575 \n",
      "Epoch 24/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8559 - loss: 0.3508 \n",
      "Epoch 25/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8608 - loss: 0.3448 \n",
      "Epoch 26/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8535 - loss: 0.3579 \n",
      "Epoch 27/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8539 - loss: 0.3541 \n",
      "Epoch 28/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8563 - loss: 0.3555 \n",
      "Epoch 29/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8562 - loss: 0.3446 \n",
      "Epoch 30/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.3405 \n",
      "Epoch 31/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8662 - loss: 0.3357 \n",
      "Epoch 32/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8602 - loss: 0.3460 \n",
      "Epoch 33/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.3478    \n",
      "Epoch 34/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8559 - loss: 0.3466 \n",
      "Epoch 35/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8639 - loss: 0.3443 \n",
      "Epoch 36/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8609 - loss: 0.3467 \n",
      "Epoch 37/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8549 - loss: 0.3489 \n",
      "Epoch 38/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8594 - loss: 0.3461 \n",
      "Epoch 39/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.3412 \n",
      "Epoch 40/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8647 - loss: 0.3404 \n",
      "Epoch 41/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8595 - loss: 0.3450 \n",
      "Epoch 42/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8641 - loss: 0.3368 \n",
      "Epoch 43/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8632 - loss: 0.3424 \n",
      "Epoch 44/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.3406 \n",
      "Epoch 45/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8600 - loss: 0.3479 \n",
      "Epoch 46/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8579 - loss: 0.3470 \n",
      "Epoch 47/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8572 - loss: 0.3512 \n",
      "Epoch 48/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8571 - loss: 0.3508 \n",
      "Epoch 49/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.3416    \n",
      "Epoch 50/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.3405 \n",
      "Epoch 51/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3371 \n",
      "Epoch 52/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8607 - loss: 0.3429 \n",
      "Epoch 53/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8627 - loss: 0.3464 \n",
      "Epoch 54/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8694 - loss: 0.3349 \n",
      "Epoch 55/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8612 - loss: 0.3434 \n",
      "Epoch 56/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8585 - loss: 0.3440 \n",
      "Epoch 57/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8613 - loss: 0.3462 \n",
      "Epoch 58/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.3419 \n",
      "Epoch 59/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8616 - loss: 0.3405 \n",
      "Epoch 60/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8673 - loss: 0.3342 \n",
      "Epoch 61/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8564 - loss: 0.3456 \n",
      "Epoch 62/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8656 - loss: 0.3368 \n",
      "Epoch 63/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8529 - loss: 0.3449 \n",
      "Epoch 64/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8553 - loss: 0.3480 \n",
      "Epoch 65/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8644 - loss: 0.3322 \n",
      "Epoch 66/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8559 - loss: 0.3468 \n",
      "Epoch 67/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8618 - loss: 0.3340 \n",
      "Epoch 68/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8596 - loss: 0.3378 \n",
      "Epoch 69/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8603 - loss: 0.3395 \n",
      "Epoch 70/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8580 - loss: 0.3481 \n",
      "Epoch 71/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.3282 \n",
      "Epoch 72/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8590 - loss: 0.3390 \n",
      "Epoch 73/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8598 - loss: 0.3387 \n",
      "Epoch 74/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8657 - loss: 0.3278 \n",
      "Epoch 75/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8622 - loss: 0.3394 \n",
      "Epoch 76/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8726 - loss: 0.3212 \n",
      "Epoch 77/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8621 - loss: 0.3340 \n",
      "Epoch 78/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8589 - loss: 0.3439 \n",
      "Epoch 79/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8581 - loss: 0.3417 \n",
      "Epoch 80/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8575 - loss: 0.3442 \n",
      "Epoch 81/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8679 - loss: 0.3225 \n",
      "Epoch 82/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8701 - loss: 0.3230 \n",
      "Epoch 83/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8570 - loss: 0.3459 \n",
      "Epoch 84/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.3329 \n",
      "Epoch 85/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8623 - loss: 0.3295 \n",
      "Epoch 86/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8657 - loss: 0.3244 \n",
      "Epoch 87/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8640 - loss: 0.3309 \n",
      "Epoch 88/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8609 - loss: 0.3392 \n",
      "Epoch 89/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8482 - loss: 0.3571 \n",
      "Epoch 90/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8529 - loss: 0.3441 \n",
      "Epoch 91/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.3448 \n",
      "Epoch 92/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 0.3426 \n",
      "Epoch 93/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8572 - loss: 0.3395 \n",
      "Epoch 94/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3349 \n",
      "Epoch 95/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8622 - loss: 0.3334 \n",
      "Epoch 96/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 0.3334 \n",
      "Epoch 97/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 0.3447 \n",
      "Epoch 98/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8613 - loss: 0.3328 \n",
      "Epoch 99/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8600 - loss: 0.3348 \n",
      "Epoch 100/100\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8614 - loss: 0.3394 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7ff5b55392a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training\n",
    "# testing\n",
    "# batch size (32 is default) = how many to run and compare all at once, number of predictions\n",
    "# number of epochs\n",
    "\n",
    "ann.fit(X_train, y_train, batch_size = 32, epochs = 100) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a4e6ae-b519-408d-a361-8cb0e8671be6",
   "metadata": {},
   "source": [
    "## Part 4 - Making the predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2fb139-4a08-415b-91aa-0e647a2a47ff",
   "metadata": {},
   "source": [
    "#### Predicting the result of a single observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fc3e923-ec86-4451-8fdc-7e1f12d3d404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# must always be a 2d array\n",
    "# 1,0,0 is France, so use ct.transform on the matrix\n",
    "# don't forget scaling!!! ... don't fit again\n",
    "customer = ct.transform([[600, 'France','Male', 40, 3, 60000, 2, 1, 1, 50000]])\n",
    "\n",
    "#customer = [[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]]\n",
    "sc_customer = sc.transform(customer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f857d7b-d993-439f-9638-4733986fc814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "Probability:  0.05583287\n"
     ]
    }
   ],
   "source": [
    "print('Probability: ', ann.predict(sc_customer)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cce2a3f2-e2dd-48aa-a750-ed788855235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n",
      "Customer Leave:  [[False]]\n"
     ]
    }
   ],
   "source": [
    "print('Customer Leave: ', ann.predict(sc_customer) > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824dac21-193b-4eeb-99d6-5cb3590472fd",
   "metadata": {},
   "source": [
    "#### Predicting the Test set results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "569a65a2-a0bd-45dd-8a78-380a3ef3e108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step  \n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 0]\n",
      " ...\n",
      " [0 0]\n",
      " [0 0]\n",
      " [0 0]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = ann.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "\n",
    "# Left side is prediction, Right side truth\n",
    "# 0 stayed, 1 left\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e0e7cc-0541-4e27-8778-1cda65b40466",
   "metadata": {},
   "source": [
    "#### Making the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f10fb7a-a17f-4af9-971b-17ede11c8c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1517   78]\n",
      " [ 199  206]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8615"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abb046e-fb77-4f64-b571-972aa44ef758",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
